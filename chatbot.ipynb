{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy \n",
    "import torch\n",
    "import json\n",
    "from nlp_utils import *\n",
    "import random"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (\"data.json\", 'r') as f:\n",
    "    intents = json.load(f)[\"intents\"]\n",
    "    \n",
    "data = torch.load(\"model.save\")\n",
    "\n",
    "model_state = data[\"model_state\"]\n",
    "\n",
    "input_size = data[\"input_size\"]\n",
    "hidden_size = data[\"hidden_size\"]\n",
    "num_classes = data[\"num_classes\"]\n",
    "\n",
    "tag_translator = data[\"tag_translator\"]\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "model.load_state_dict(model_state)\n",
    "model.eval()\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type 'quit' to quit.\n",
      "\tYou: hello there \n",
      "\tChatBot: Hi human, please tell me your GeniSys user\n",
      "\n",
      "prob: 1.0 | tag: Greeting\n",
      "\n",
      "\n",
      "\tYou: my name is alice \n",
      "\tChatBot: You are <HUMAN>! How can I help?\n",
      "\n",
      "prob: 0.914756178855896 | tag: CurrentHumanQuery\n",
      "\n",
      "\n",
      "\tYou: who am i \n",
      "\tChatBot: Please look at the camera\n",
      "\n",
      "prob: 0.9991425275802612 | tag: WhoAmI\n",
      "\n",
      "\n",
      "\tYou: how are you \n",
      "\tChatBot: Hello, I am good thank you, how are you? Please tell me your GeniSys user\n",
      "\n",
      "prob: 0.9999338388442993 | tag: CourtesyGreeting\n",
      "\n",
      "\n",
      "\tYou: are you good\n",
      "\tChatBot: Hi, how are you? I am great thanks! Please tell me your GeniSys user\n",
      "\n",
      "prob: 0.7716938853263855 | tag: CourtesyGreeting\n",
      "\n",
      "\n",
      "\tYou: what do you call me \n",
      "\tChatBot: You are <HUMAN>! How can I help?\n",
      "\n",
      "prob: 0.9907564520835876 | tag: CurrentHumanQuery\n",
      "\n",
      "\n",
      "\tYou: alice\n",
      "\tChatBot: I’m sorry, I’m afraid I can’t do that!\n",
      "\n",
      "prob: 0.9101258516311646 | tag: PodBayDoor\n",
      "\n",
      "\n",
      "\tYou: door\n",
      "\tChatBot: I’m sorry, I’m afraid I can’t do that!\n",
      "\n",
      "prob: 1.0 | tag: PodBayDoor\n",
      "\n",
      "\n",
      "\tYou: tell me a joke\n",
      "\tChatBot: Two cows standing next to each other in a field. Daisy says to Dolly, 'I was artificially inseminated this morning.' 'I don't believe you', said Dolly. 'It's true, no bull!' exclaimed Daisy.\n",
      "\n",
      "prob: 1.0 | tag: Jokes\n",
      "\n",
      "\n",
      "\tYou: cum\n",
      "\tChatBot: How rude\n",
      "\n",
      "prob: 0.9976714253425598 | tag: Swearing\n",
      "\n",
      "\n",
      "\tYou: \n",
      "\tChatBot: See you later\n",
      "\n",
      "prob: 0.9749454259872437 | tag: GoodBye\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Type 'quit' to quit.\")\n",
    "\n",
    "user_input = \"\"\n",
    "\n",
    "tag = \"\"\n",
    "\n",
    "\n",
    "# while user_input != \"quit\":\n",
    "while tag != \"GoodBye\":\n",
    "    user_input = input()\n",
    "    print(\"\\tYou:\",user_input)\n",
    "    \n",
    "    user_input_vector = torch.from_numpy(tokenize_to_vec(user_input, nlp))\n",
    "    user_input_vector = user_input_vector.reshape(1, user_input_vector.shape[0])\n",
    "    user_input_vector = user_input_vector.to(device)\n",
    "    \n",
    "    output = model(user_input_vector)\n",
    "    _, prediction = torch.max(output, dim=1)\n",
    "\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    prob = probs[0][prediction.item()]\n",
    "\n",
    "\n",
    "    if prob >= 0.75: \n",
    "        # get tag\n",
    "        for key in tag_translator:\n",
    "            if tag_translator[key] == prediction.item():\n",
    "                tag = key\n",
    "        # get response\n",
    "        for intent in intents:\n",
    "            if intent[\"intent\"] == tag:\n",
    "                print(\"\\tChatBot:\", random.choice(intent[\"responses\"]))\n",
    "                print()\n",
    "                print(\"prob:\", prob.item(), \"| tag:\", tag)\n",
    "                print()\n",
    "                print()\n",
    "    else:\n",
    "        print(\"prob:\", prob.item())\n",
    "        print(\"Chatbot: I don't understand.\")\n",
    "        print()\n",
    "        print()\n",
    "            \n",
    "        \n",
    "    \n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1167e92537cce41ea14d51960ff1ea806f7312a9aa6fa52755eaf0bd3b06b5d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
